
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://docs.tinygrad.org/tensor/movement/">
      
      
        <link rel="prev" href="../creation/">
      
      
        <link rel="next" href="../ops/">
      
      
      <link rel="icon" href="../../favicon.svg">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.30">
    
    
      
        <title>Movement - tinygrad docs</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.3cba04c6.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_markdown_exec_pyodide.css">
    
      <link rel="stylesheet" href="../../assets/_markdown_exec_ansi.css">
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="lime">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#movement-low-level" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="tinygrad docs" class="md-header__button md-logo" aria-label="tinygrad docs" data-md-component="logo">
      
  <img src="../../logo_tiny_dark.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            tinygrad docs
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Movement
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="lime"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="lime"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="lime"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/tinygrad/tinygrad/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



  

<nav class="md-nav md-nav--primary md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="tinygrad docs" class="md-nav__button md-logo" aria-label="tinygrad docs" data-md-component="logo">
      
  <img src="../../logo_tiny_dark.svg" alt="logo">

    </a>
    tinygrad docs
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/tinygrad/tinygrad/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../.." class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Home
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_1" id="__nav_1_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            Home
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../quickstart/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quickstart
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../showcase/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Showcase
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../mnist/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    MNIST Tutorial
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1_5" checked>
        
          
          <label class="md-nav__link" for="__nav_1_5" id="__nav_1_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    API Reference
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_1_5">
            <span class="md-nav__icon md-icon"></span>
            API Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1_5_1" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Tensor
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_1_5_1" id="__nav_1_5_1_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_1_5_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_1_5_1">
            <span class="md-nav__icon md-icon"></span>
            Tensor
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../creation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Creation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Movement
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Movement
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#movement-low-level" class="md-nav__link">
    <span class="md-ellipsis">
      Movement (low level)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Movement (low level)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tinygrad.Tensor.view" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;view
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tinygrad.Tensor.reshape" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;reshape
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tinygrad.Tensor.expand" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;expand
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tinygrad.Tensor.permute" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;permute
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tinygrad.Tensor.flip" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;flip
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tinygrad.Tensor.shrink" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;shrink
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tinygrad.Tensor.pad" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;pad
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#movement-high-level" class="md-nav__link">
    <span class="md-ellipsis">
      Movement (high level)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Movement (high level)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tinygrad.Tensor.gather" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;gather
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tinygrad.Tensor.cat" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;cat
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tinygrad.Tensor.stack" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;stack
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tinygrad.Tensor.repeat" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;repeat
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tinygrad.Tensor.repeat_interleave" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;repeat_interleave
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tinygrad.Tensor.split" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;split
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tinygrad.Tensor.chunk" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;chunk
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tinygrad.Tensor.squeeze" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;squeeze
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tinygrad.Tensor.unsqueeze" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;unsqueeze
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tinygrad.Tensor.pad2d" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;pad2d
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tinygrad.Tensor.T" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;T
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tinygrad.Tensor.transpose" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;transpose
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tinygrad.Tensor.flatten" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;flatten
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tinygrad.Tensor.unflatten" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;unflatten
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Ops
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../function/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Function
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dtypes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    dtypes
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../nn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    nn (Neural Networks)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../env_vars/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Environment Variables
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1_6" >
        
          
          <label class="md-nav__link" for="__nav_1_6" id="__nav_1_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Developer
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_1_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1_6">
            <span class="md-nav__icon md-icon"></span>
            Developer
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../developer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Developer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_1_6_2" >
        
          
          <label class="md-nav__link" for="__nav_1_6_2" id="__nav_1_6_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Runtime
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_1_6_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1_6_2">
            <span class="md-nav__icon md-icon"></span>
            Runtime
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../runtime/overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Runtime Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../runtime/hcq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    HCQ
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tinybox/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    tinybox
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/tinygrad/tinygrad/edit/master/docs/tensor/movement.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4v-2m10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1 2.1 2.1Z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/tinygrad/tinygrad/raw/master/docs/tensor/movement.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.15 8.15 0 0 1-1.23-2Z"/></svg>
    </a>
  


  <h1>Movement</h1>

<h2 id="movement-low-level">Movement (low level)<a class="headerlink" href="#movement-low-level" title="Permanent link">¤</a></h2>


<div class="doc doc-object doc-function">


<h3 id="tinygrad.Tensor.view" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">view</span>


<a href="#tinygrad.Tensor.view" class="headerlink" title="Permanent link">¤</a></h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span class="nf">view</span><span class="p">(</span><span class="o">*</span><span class="n">shape</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor" href="../#tinygrad.Tensor">Tensor</a></span>
</code></pre></div>

    <div class="doc doc-contents first">

      <p><code class="language-python highlight"><span class="o">.</span><span class="n">view</span></code> is an alias for <code class="language-python highlight"><span class="o">.</span><span class="n">reshape</span></code>.</p>

            <details class="quote">
              <summary>Source code in <code>tinygrad/tensor.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">view</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">shape</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;`.view` is an alias for `.reshape`.&quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tinygrad.Tensor.reshape" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">reshape</span>


<a href="#tinygrad.Tensor.reshape" class="headerlink" title="Permanent link">¤</a></h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span class="nf">reshape</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor" href="../#tinygrad.Tensor">Tensor</a></span>
</code></pre></div>

    <div class="doc doc-contents first">

      <p>Returns a tensor with the same data as the original tensor but with a different shape.
<code class="language-python highlight"><span class="n">shape</span></code> can be passed as a tuple or as separate arguments.</p>
<div class="language-python highlight"><pre><span></span><code><span class="n">t</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">[[</span><span class="mi">0</span> <span class="mi">1</span> <span class="mi">2</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">3</span> <span class="mi">4</span> <span class="mi">5</span><span class="p">]]</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>tinygrad/tensor.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">reshape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Returns a tensor with the same data as the original tensor but with a different shape.</span>
<span class="sd">  `shape` can be passed as a tuple or as separate arguments.</span>

<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  t = Tensor.arange(6)</span>
<span class="sd">  print(t.reshape(2, 3).numpy())</span>
<span class="sd">  ```</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># resolve None and args</span>
  <span class="n">new_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">s</span> <span class="k">if</span> <span class="n">s</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">argfix</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">))])</span>
  <span class="c1"># resolve -1</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">c</span> <span class="o">:=</span> <span class="n">new_shape</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;only one dimension can be inferred using -1, getting </span><span class="si">{</span><span class="n">new_shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">c</span><span class="p">:</span> <span class="n">new_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="o">-</span><span class="n">prod</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">//</span> <span class="n">prod</span><span class="p">(</span><span class="n">new_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">s</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span> <span class="k">else</span> <span class="n">s</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">new_shape</span><span class="p">])</span>
  <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">Reshape</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">new_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">new_shape</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="k">else</span> <span class="bp">self</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tinygrad.Tensor.expand" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">expand</span>


<a href="#tinygrad.Tensor.expand" class="headerlink" title="Permanent link">¤</a></h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span class="nf">expand</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor" href="../#tinygrad.Tensor">Tensor</a></span>
</code></pre></div>

    <div class="doc doc-contents first">

      <p>Returns a tensor that is expanded to the shape that is specified.
Expand can also increase the number of dimensions that a tensor has.</p>
<p>Passing a <code class="language-python highlight"><span class="o">-</span><span class="mi">1</span></code> or <code class="language-python highlight"><span class="kc">None</span></code> to a dimension means that its size will not be changed.</p>
<div class="language-python highlight"><pre><span></span><code><span class="n">t</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">[[</span><span class="mi">1</span> <span class="mi">2</span> <span class="mi">3</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">1</span> <span class="mi">2</span> <span class="mi">3</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">1</span> <span class="mi">2</span> <span class="mi">3</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">1</span> <span class="mi">2</span> <span class="mi">3</span><span class="p">]]</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>tinygrad/tensor.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">expand</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Returns a tensor that is expanded to the shape that is specified.</span>
<span class="sd">  Expand can also increase the number of dimensions that a tensor has.</span>

<span class="sd">  Passing a `-1` or `None` to a dimension means that its size will not be changed.</span>

<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  t = Tensor([1, 2, 3])</span>
<span class="sd">  print(t.expand(4, -1).numpy())</span>
<span class="sd">  ```</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_broadcast_to</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">from_</span> <span class="k">if</span> <span class="n">to</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span> <span class="ow">or</span> <span class="n">to</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">to</span> <span class="k">for</span> <span class="n">from_</span><span class="p">,</span> <span class="n">to</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="n">_pad_left</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">argfix</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">))))))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tinygrad.Tensor.permute" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">permute</span>


<a href="#tinygrad.Tensor.permute" class="headerlink" title="Permanent link">¤</a></h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span class="nf">permute</span><span class="p">(</span><span class="n">order</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor" href="../#tinygrad.Tensor">Tensor</a></span>
</code></pre></div>

    <div class="doc doc-contents first">

      <p>Returns a tensor that is a permutation of the original tensor.
The new tensor has the same data as the original tensor but with the dimensions permuted according to the order specified.
<code class="language-python highlight"><span class="n">order</span></code> can be passed as a tuple or as separate arguments.</p>
<p><div class="language-python highlight"><pre><span></span><code><span class="n">t</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">[[</span><span class="mi">0</span> <span class="mi">1</span> <span class="mi">2</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">3</span> <span class="mi">4</span> <span class="mi">5</span><span class="p">]]</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">[[</span><span class="mi">0</span> <span class="mi">3</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">1</span> <span class="mi">4</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">2</span> <span class="mi">5</span><span class="p">]]</span>
</code></pre></div></p>

            <details class="quote">
              <summary>Source code in <code>tinygrad/tensor.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">permute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">order</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Returns a tensor that is a permutation of the original tensor.</span>
<span class="sd">  The new tensor has the same data as the original tensor but with the dimensions permuted according to the order specified.</span>
<span class="sd">  `order` can be passed as a tuple or as separate arguments.</span>

<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  t = Tensor.arange(6).reshape(2, 3)</span>
<span class="sd">  print(t.numpy())</span>
<span class="sd">  ```</span>
<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  print(t.permute(1, 0).numpy())</span>
<span class="sd">  ```</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">order_arg</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_resolve_dim</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">argfix</span><span class="p">(</span><span class="n">order</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">))</span>
  <span class="k">if</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">order_arg</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="p">)):</span> <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;order is not a valid permutation, getting </span><span class="si">{</span><span class="n">order_arg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">Permute</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="n">order_arg</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tinygrad.Tensor.flip" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">flip</span>


<a href="#tinygrad.Tensor.flip" class="headerlink" title="Permanent link">¤</a></h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span class="nf">flip</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor" href="../#tinygrad.Tensor">Tensor</a></span>
</code></pre></div>

    <div class="doc doc-contents first">

      <p>Returns a tensor that reverses the order of the original tensor along given <code class="language-python highlight"><span class="n">axis</span></code>.
<code class="language-python highlight"><span class="n">axis</span></code> can be passed as a tuple or as separate arguments.</p>
<p><div class="language-python highlight"><pre><span></span><code><span class="n">t</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">[[</span><span class="mi">0</span> <span class="mi">1</span> <span class="mi">2</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">3</span> <span class="mi">4</span> <span class="mi">5</span><span class="p">]]</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">[[</span><span class="mi">3</span> <span class="mi">4</span> <span class="mi">5</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">0</span> <span class="mi">1</span> <span class="mi">2</span><span class="p">]]</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">flip</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">[[</span><span class="mi">5</span> <span class="mi">4</span> <span class="mi">3</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">2</span> <span class="mi">1</span> <span class="mi">0</span><span class="p">]]</span>
</code></pre></div></p>

            <details class="quote">
              <summary>Source code in <code>tinygrad/tensor.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span>
<span class="normal">829</span>
<span class="normal">830</span>
<span class="normal">831</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">flip</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Returns a tensor that reverses the order of the original tensor along given `axis`.</span>
<span class="sd">  `axis` can be passed as a tuple or as separate arguments.</span>

<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  t = Tensor.arange(6).reshape(2, 3)</span>
<span class="sd">  print(t.numpy())</span>
<span class="sd">  ```</span>
<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  print(t.flip(0).numpy())</span>
<span class="sd">  ```</span>
<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  print(t.flip((0, 1)).numpy())</span>
<span class="sd">  ```</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">axis_arg</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_resolve_dim</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">argfix</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">))</span>
  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">axis_arg</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dedup</span><span class="p">(</span><span class="n">axis_arg</span><span class="p">)):</span> <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;dim can appear at least once, getting </span><span class="si">{</span><span class="n">axis_arg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">Flip</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis_arg</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tinygrad.Tensor.shrink" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">shrink</span>


<a href="#tinygrad.Tensor.shrink" class="headerlink" title="Permanent link">¤</a></h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span class="nf">shrink</span><span class="p">(</span>
    <span class="n">arg</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Tuple" href="https://docs.python.org/3/library/typing.html#typing.Tuple">Tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="typing.Optional" href="https://docs.python.org/3/library/typing.html#typing.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="typing.Tuple" href="https://docs.python.org/3/library/typing.html#typing.Tuple">Tuple</a></span><span class="p">[</span><span class="n"><span title="tinygrad.shape.symbolic.sint">sint</span></span><span class="p">,</span> <span class="n"><span title="tinygrad.shape.symbolic.sint">sint</span></span><span class="p">]],</span> <span class="o">...</span><span class="p">]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor" href="../#tinygrad.Tensor">Tensor</a></span>
</code></pre></div>

    <div class="doc doc-contents first">

      <p>Returns a tensor that shrinks the each axis based on input arg.
<code class="language-python highlight"><span class="n">arg</span></code> must have the same length as <code class="language-python highlight"><span class="bp">self</span><span class="o">.</span><span class="n">ndim</span></code>.
For each axis, it can be <code class="language-python highlight"><span class="kc">None</span></code>, which means no shrink, or a tuple <code class="language-python highlight"><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">)</span></code> that works the same as Python slice.</p>
<p><div class="language-python highlight"><pre><span></span><code><span class="n">t</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">9</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">[[</span><span class="mi">0</span> <span class="mi">1</span> <span class="mi">2</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">3</span> <span class="mi">4</span> <span class="mi">5</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">6</span> <span class="mi">7</span> <span class="mi">8</span><span class="p">]]</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">shrink</span><span class="p">(((</span><span class="kc">None</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">))))</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">[[</span><span class="mi">1</span> <span class="mi">2</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">4</span> <span class="mi">5</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">7</span> <span class="mi">8</span><span class="p">]]</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">shrink</span><span class="p">((((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">))))</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">[[</span><span class="mi">0</span> <span class="mi">1</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">3</span> <span class="mi">4</span><span class="p">]]</span>
</code></pre></div></p>

            <details class="quote">
              <summary>Source code in <code>tinygrad/tensor.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">833</span>
<span class="normal">834</span>
<span class="normal">835</span>
<span class="normal">836</span>
<span class="normal">837</span>
<span class="normal">838</span>
<span class="normal">839</span>
<span class="normal">840</span>
<span class="normal">841</span>
<span class="normal">842</span>
<span class="normal">843</span>
<span class="normal">844</span>
<span class="normal">845</span>
<span class="normal">846</span>
<span class="normal">847</span>
<span class="normal">848</span>
<span class="normal">849</span>
<span class="normal">850</span>
<span class="normal">851</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">shrink</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg</span><span class="p">:</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">sint</span><span class="p">,</span> <span class="n">sint</span><span class="p">]],</span> <span class="o">...</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Returns a tensor that shrinks the each axis based on input arg.</span>
<span class="sd">  `arg` must have the same length as `self.ndim`.</span>
<span class="sd">  For each axis, it can be `None`, which means no shrink, or a tuple `(start, end)` that works the same as Python slice.</span>

<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  t = Tensor.arange(9).reshape(3, 3)</span>
<span class="sd">  print(t.numpy())</span>
<span class="sd">  ```</span>
<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  print(t.shrink(((None, (1, 3)))).numpy())</span>
<span class="sd">  ```</span>
<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  print(t.shrink((((0, 2), (0, 2)))).numpy())</span>
<span class="sd">  ```</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">x</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">x</span> <span class="o">==</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span><span class="n">s</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">arg</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)):</span> <span class="k">return</span> <span class="bp">self</span>
  <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">Shrink</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(</span><span class="n">x</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span><span class="n">s</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">arg</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tinygrad.Tensor.pad" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">pad</span>


<a href="#tinygrad.Tensor.pad" class="headerlink" title="Permanent link">¤</a></h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span class="nf">pad</span><span class="p">(</span>
    <span class="n">arg</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Tuple" href="https://docs.python.org/3/library/typing.html#typing.Tuple">Tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="typing.Optional" href="https://docs.python.org/3/library/typing.html#typing.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-external" title="typing.Tuple" href="https://docs.python.org/3/library/typing.html#typing.Tuple">Tuple</a></span><span class="p">[</span><span class="n"><span title="tinygrad.shape.symbolic.sint">sint</span></span><span class="p">,</span> <span class="n"><span title="tinygrad.shape.symbolic.sint">sint</span></span><span class="p">]],</span> <span class="o">...</span><span class="p">],</span>
    <span class="n">value</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor.float" href="../ops/#tinygrad.Tensor.float">float</a></span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor" href="../#tinygrad.Tensor">Tensor</a></span>
</code></pre></div>

    <div class="doc doc-contents first">

      <p>Returns a tensor that pads the each axis based on input arg.
<code class="language-python highlight"><span class="n">arg</span></code> must have the same length as <code class="language-python highlight"><span class="bp">self</span><span class="o">.</span><span class="n">ndim</span></code>.
For each axis, it can be <code class="language-python highlight"><span class="kc">None</span></code>, which means no pad, or a tuple <code class="language-python highlight"><span class="p">(</span><span class="n">pad_before</span><span class="p">,</span> <span class="n">pad_after</span><span class="p">)</span></code>.
If <code class="language-python highlight"><span class="n">value</span></code> is specified, the tensor is padded with <code class="language-python highlight"><span class="n">value</span></code> instead of <code class="language-python highlight"><span class="mf">0.0</span></code>.</p>
<p><div class="language-python highlight"><pre><span></span><code><span class="n">t</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">[[</span><span class="mi">0</span> <span class="mi">1</span> <span class="mi">2</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">3</span> <span class="mi">4</span> <span class="mi">5</span><span class="p">]]</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">pad</span><span class="p">(((</span><span class="kc">None</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))))</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">[[</span><span class="mi">0</span> <span class="mi">0</span> <span class="mi">1</span> <span class="mi">2</span> <span class="mi">0</span> <span class="mi">0</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">0</span> <span class="mi">3</span> <span class="mi">4</span> <span class="mi">5</span> <span class="mi">0</span> <span class="mi">0</span><span class="p">]]</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">pad</span><span class="p">(((</span><span class="kc">None</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))),</span> <span class="o">-</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">[[</span><span class="o">-</span><span class="mi">2</span>  <span class="mi">0</span>  <span class="mi">1</span>  <span class="mi">2</span> <span class="o">-</span><span class="mi">2</span> <span class="o">-</span><span class="mi">2</span><span class="p">]</span>
 <span class="p">[</span><span class="o">-</span><span class="mi">2</span>  <span class="mi">3</span>  <span class="mi">4</span>  <span class="mi">5</span> <span class="o">-</span><span class="mi">2</span> <span class="o">-</span><span class="mi">2</span><span class="p">]]</span>
</code></pre></div></p>

            <details class="quote">
              <summary>Source code in <code>tinygrad/tensor.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">853</span>
<span class="normal">854</span>
<span class="normal">855</span>
<span class="normal">856</span>
<span class="normal">857</span>
<span class="normal">858</span>
<span class="normal">859</span>
<span class="normal">860</span>
<span class="normal">861</span>
<span class="normal">862</span>
<span class="normal">863</span>
<span class="normal">864</span>
<span class="normal">865</span>
<span class="normal">866</span>
<span class="normal">867</span>
<span class="normal">868</span>
<span class="normal">869</span>
<span class="normal">870</span>
<span class="normal">871</span>
<span class="normal">872</span>
<span class="normal">873</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">pad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg</span><span class="p">:</span><span class="n">Tuple</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">sint</span><span class="p">,</span> <span class="n">sint</span><span class="p">]],</span> <span class="o">...</span><span class="p">],</span> <span class="n">value</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Returns a tensor that pads the each axis based on input arg.</span>
<span class="sd">  `arg` must have the same length as `self.ndim`.</span>
<span class="sd">  For each axis, it can be `None`, which means no pad, or a tuple `(pad_before, pad_after)`.</span>
<span class="sd">  If `value` is specified, the tensor is padded with `value` instead of `0.0`.</span>

<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  t = Tensor.arange(6).reshape(2, 3)</span>
<span class="sd">  print(t.numpy())</span>
<span class="sd">  ```</span>
<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  print(t.pad(((None, (1, 2)))).numpy())</span>
<span class="sd">  ```</span>
<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  print(t.pad(((None, (1, 2))), -2).numpy())</span>
<span class="sd">  ```</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="n">x</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">x</span> <span class="o">==</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">arg</span><span class="p">):</span> <span class="k">return</span> <span class="bp">self</span>
  <span class="n">ret</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">Pad</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">arg</span><span class="o">=</span><span class="p">(</span><span class="n">narg</span><span class="o">:=</span><span class="nb">tuple</span><span class="p">(</span><span class="n">x</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">arg</span><span class="p">)))</span>
  <span class="k">return</span> <span class="n">ret</span> <span class="k">if</span> <span class="mi">0</span> <span class="o">==</span> <span class="n">value</span> <span class="k">else</span> <span class="n">ret</span> <span class="o">+</span> <span class="n">F</span><span class="o">.</span><span class="n">Pad</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">Tensor</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="bp">self</span><span class="p">),</span> <span class="n">arg</span><span class="o">=</span><span class="n">narg</span><span class="p">)</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div><h2 id="movement-high-level">Movement (high level)<a class="headerlink" href="#movement-high-level" title="Permanent link">¤</a></h2>


<div class="doc doc-object doc-function">


<h3 id="tinygrad.Tensor.gather" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">gather</span>


<a href="#tinygrad.Tensor.gather" class="headerlink" title="Permanent link">¤</a></h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span class="nf">gather</span><span class="p">(</span><span class="n">dim</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor.int" href="../ops/#tinygrad.Tensor.int">int</a></span><span class="p">,</span> <span class="n">index</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor" href="../#tinygrad.Tensor">Tensor</a></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor" href="../#tinygrad.Tensor">Tensor</a></span>
</code></pre></div>

    <div class="doc doc-contents first">

      <p>Gathers values along an axis specified by <code class="language-python highlight"><span class="n">dim</span></code>.</p>
<p><div class="language-python highlight"><pre><span></span><code><span class="n">t</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">[[</span><span class="mi">1</span> <span class="mi">2</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">3</span> <span class="mi">4</span><span class="p">]]</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]))</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">[[</span><span class="mi">1</span> <span class="mi">1</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">4</span> <span class="mi">3</span><span class="p">]]</span>
</code></pre></div></p>

            <details class="quote">
              <summary>Source code in <code>tinygrad/tensor.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span>
<span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span>
<span class="normal">1047</span>
<span class="normal">1048</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">gather</span><span class="p">(</span><span class="bp">self</span><span class="p">:</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Gathers values along an axis specified by `dim`.</span>

<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  t = Tensor([[1, 2], [3, 4]])</span>
<span class="sd">  print(t.numpy())</span>
<span class="sd">  ```</span>
<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  print(t.gather(1, Tensor([[0, 0], [1, 0]])).numpy())</span>
<span class="sd">  ```</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">assert</span> <span class="n">index</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;self.ndim must equal index.ndim, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="si">=}</span><span class="s2">, </span><span class="si">{</span><span class="n">index</span><span class="o">.</span><span class="n">ndim</span><span class="si">=}</span><span class="s2">&quot;</span>
  <span class="n">dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_resolve_dim</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
  <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="n">s</span> <span class="o">&gt;=</span> <span class="n">i</span> <span class="k">for</span> <span class="n">d</span><span class="p">,(</span><span class="n">s</span><span class="p">,</span><span class="n">i</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">index</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span> <span class="k">if</span> <span class="n">d</span> <span class="o">!=</span> <span class="n">dim</span><span class="p">),</span> <span class="s2">&quot;requires self.shape[d] &gt;= index.shape[d] for all d != dim&quot;</span>
  <span class="n">index</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
  <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shrink</span><span class="p">(</span><span class="nb">tuple</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">if</span> <span class="n">d</span> <span class="o">!=</span> <span class="n">dim</span> <span class="k">else</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">d</span><span class="p">,</span><span class="n">i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">index</span><span class="o">.</span><span class="n">shape</span><span class="p">)))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
  <span class="k">return</span> <span class="p">((</span><span class="n">index</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">))</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">acc_dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tinygrad.Tensor.cat" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">cat</span>


<a href="#tinygrad.Tensor.cat" class="headerlink" title="Permanent link">¤</a></h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span class="nf">cat</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor" href="../#tinygrad.Tensor">Tensor</a></span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor.int" href="../ops/#tinygrad.Tensor.int">int</a></span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor" href="../#tinygrad.Tensor">Tensor</a></span>
</code></pre></div>

    <div class="doc doc-contents first">

      <p>Concatenates self with other <code class="language-python highlight"><span class="n">Tensor</span></code> in <code class="language-python highlight"><span class="n">args</span></code> along an axis specified by <code class="language-python highlight"><span class="n">dim</span></code>.
All tensors must have the same shape except in the concatenating dimension.</p>
<p><div class="language-python highlight"><pre><span></span><code><span class="n">t0</span><span class="p">,</span> <span class="n">t1</span><span class="p">,</span> <span class="n">t2</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]),</span> <span class="n">Tensor</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]),</span> <span class="n">Tensor</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">t0</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">[[</span><span class="mi">1</span> <span class="mi">2</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">3</span> <span class="mi">4</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">5</span> <span class="mi">6</span><span class="p">]]</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">t0</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">[[</span><span class="mi">1</span> <span class="mi">2</span> <span class="mi">3</span> <span class="mi">4</span> <span class="mi">5</span> <span class="mi">6</span><span class="p">]]</span>
</code></pre></div></p>

            <details class="quote">
              <summary>Source code in <code>tinygrad/tensor.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">cat</span><span class="p">(</span><span class="bp">self</span><span class="p">:</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Concatenates self with other `Tensor` in `args` along an axis specified by `dim`.</span>
<span class="sd">  All tensors must have the same shape except in the concatenating dimension.</span>

<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  t0, t1, t2 = Tensor([[1, 2]]), Tensor([[3, 4]]), Tensor([[5, 6]])</span>
<span class="sd">  print(t0.cat(t1, t2, dim=0).numpy())</span>
<span class="sd">  ```</span>
<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  print(t0.cat(t1, t2, dim=1).numpy())</span>
<span class="sd">  ```</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_resolve_dim</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
  <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">s</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">s</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">dim</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">args</span><span class="p">)</span>
  <span class="n">catargs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">]</span>
  <span class="n">cat_dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">catargs</span><span class="p">]</span>
  <span class="n">cat_dim_cumsum</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">*</span><span class="n">itertools</span><span class="o">.</span><span class="n">accumulate</span><span class="p">(</span><span class="n">cat_dims</span><span class="p">)]</span>
  <span class="n">slc</span><span class="p">:</span><span class="n">List</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">sint</span><span class="p">,</span> <span class="n">sint</span><span class="p">]]]]</span> <span class="o">=</span> <span class="p">[[</span><span class="kc">None</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">catargs</span><span class="p">]</span>
  <span class="k">for</span> <span class="n">d</span><span class="p">,</span><span class="n">k</span><span class="p">,</span><span class="n">s</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">cat_dims</span><span class="p">,</span> <span class="n">cat_dim_cumsum</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">slc</span><span class="p">):</span> <span class="n">s</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">cat_dim_cumsum</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">k</span> <span class="o">-</span> <span class="n">d</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">functools</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">Tensor</span><span class="o">.</span><span class="fm">__add__</span><span class="p">,</span> <span class="p">[</span><span class="n">arg</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">s</span><span class="p">))</span> <span class="k">for</span> <span class="n">arg</span><span class="p">,</span><span class="n">s</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">catargs</span><span class="p">,</span> <span class="n">slc</span><span class="p">)])</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tinygrad.Tensor.stack" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">stack</span>


<a href="#tinygrad.Tensor.stack" class="headerlink" title="Permanent link">¤</a></h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span class="nf">stack</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor" href="../#tinygrad.Tensor">Tensor</a></span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor.int" href="../ops/#tinygrad.Tensor.int">int</a></span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor" href="../#tinygrad.Tensor">Tensor</a></span>
</code></pre></div>

    <div class="doc doc-contents first">

      <p>Concatenates self with other <code class="language-python highlight"><span class="n">Tensor</span></code> in <code class="language-python highlight"><span class="n">args</span></code> along a new dimension specified by <code class="language-python highlight"><span class="n">dim</span></code>.</p>
<p><div class="language-python highlight"><pre><span></span><code><span class="n">t0</span><span class="p">,</span> <span class="n">t1</span><span class="p">,</span> <span class="n">t2</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]),</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">t0</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">[[</span><span class="mi">1</span> <span class="mi">2</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">3</span> <span class="mi">4</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">5</span> <span class="mi">6</span><span class="p">]]</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">t0</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">[[</span><span class="mi">1</span> <span class="mi">3</span> <span class="mi">5</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">2</span> <span class="mi">4</span> <span class="mi">6</span><span class="p">]]</span>
</code></pre></div></p>

            <details class="quote">
              <summary>Source code in <code>tinygrad/tensor.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span>
<span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">stack</span><span class="p">(</span><span class="bp">self</span><span class="p">:</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Concatenates self with other `Tensor` in `args` along a new dimension specified by `dim`.</span>

<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  t0, t1, t2 = Tensor([1, 2]), Tensor([3, 4]), Tensor([5, 6])</span>
<span class="sd">  print(t0.stack(t1, t2, dim=0).numpy())</span>
<span class="sd">  ```</span>
<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  print(t0.stack(t1, t2, dim=1).numpy())</span>
<span class="sd">  ```</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># checks for shapes and number of dimensions delegated to cat</span>
  <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">t</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">args</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tinygrad.Tensor.repeat" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">repeat</span>


<a href="#tinygrad.Tensor.repeat" class="headerlink" title="Permanent link">¤</a></h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span class="nf">repeat</span><span class="p">(</span><span class="n">repeats</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor" href="../#tinygrad.Tensor">Tensor</a></span>
</code></pre></div>

    <div class="doc doc-contents first">

      <p>Repeats tensor number of times along each dimension specified by <code class="language-python highlight"><span class="n">repeats</span></code>.
<code class="language-python highlight"><span class="n">repeats</span></code> can be passed as a tuple or as separate arguments.</p>
<p><div class="language-python highlight"><pre><span></span><code><span class="n">t</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">[[</span><span class="mi">1</span> <span class="mi">2</span> <span class="mi">3</span> <span class="mi">1</span> <span class="mi">2</span> <span class="mi">3</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">1</span> <span class="mi">2</span> <span class="mi">3</span> <span class="mi">1</span> <span class="mi">2</span> <span class="mi">3</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">1</span> <span class="mi">2</span> <span class="mi">3</span> <span class="mi">1</span> <span class="mi">2</span> <span class="mi">3</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">1</span> <span class="mi">2</span> <span class="mi">3</span> <span class="mi">1</span> <span class="mi">2</span> <span class="mi">3</span><span class="p">]]</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</code></pre></div></p>

            <details class="quote">
              <summary>Source code in <code>tinygrad/tensor.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span>
<span class="normal">1105</span>
<span class="normal">1106</span>
<span class="normal">1107</span>
<span class="normal">1108</span>
<span class="normal">1109</span>
<span class="normal">1110</span>
<span class="normal">1111</span>
<span class="normal">1112</span>
<span class="normal">1113</span>
<span class="normal">1114</span>
<span class="normal">1115</span>
<span class="normal">1116</span>
<span class="normal">1117</span>
<span class="normal">1118</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">repeat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">repeats</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Repeats tensor number of times along each dimension specified by `repeats`.</span>
<span class="sd">  `repeats` can be passed as a tuple or as separate arguments.</span>

<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  t = Tensor([1, 2, 3])</span>
<span class="sd">  print(t.repeat(4, 2).numpy())</span>
<span class="sd">  ```</span>
<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  print(t.repeat(4, 2, 1).shape)</span>
<span class="sd">  ```</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">repeats</span> <span class="o">=</span> <span class="n">argfix</span><span class="p">(</span><span class="n">repeats</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>
  <span class="n">base_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">repeats</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span>
  <span class="n">new_shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">base_shape</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">b</span><span class="p">]]</span>
  <span class="n">expand_shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">rs</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">repeats</span><span class="p">,</span> <span class="n">base_shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">rs</span><span class="p">]</span>
  <span class="n">final_shape</span> <span class="o">=</span> <span class="p">[</span><span class="n">r</span><span class="o">*</span><span class="n">s</span> <span class="k">for</span> <span class="n">r</span><span class="p">,</span><span class="n">s</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">repeats</span><span class="p">,</span> <span class="n">base_shape</span><span class="p">)]</span>
  <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">new_shape</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">expand_shape</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">final_shape</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tinygrad.Tensor.repeat_interleave" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">repeat_interleave</span>


<a href="#tinygrad.Tensor.repeat_interleave" class="headerlink" title="Permanent link">¤</a></h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span class="nf">repeat_interleave</span><span class="p">(</span>
    <span class="n">repeats</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor.int" href="../ops/#tinygrad.Tensor.int">int</a></span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Optional" href="https://docs.python.org/3/library/typing.html#typing.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor.int" href="../ops/#tinygrad.Tensor.int">int</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor" href="../#tinygrad.Tensor">Tensor</a></span>
</code></pre></div>

    <div class="doc doc-contents first">

      <p>Repeat elements of a tensor.</p>
<div class="language-python highlight"><pre><span></span><code><span class="n">t</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">[</span><span class="mi">1</span> <span class="mi">1</span> <span class="mi">2</span> <span class="mi">2</span> <span class="mi">3</span> <span class="mi">3</span><span class="p">]</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>tinygrad/tensor.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">repeat_interleave</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">repeats</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span><span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Repeat elements of a tensor.</span>

<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  t = Tensor([1, 2, 3])</span>
<span class="sd">  print(t.repeat_interleave(2).numpy())</span>
<span class="sd">  ```</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">x</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="mi">0</span><span class="p">)</span> <span class="k">if</span> <span class="n">dim</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
  <span class="n">shp</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
  <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">shp</span><span class="p">[:</span><span class="n">dim</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">shp</span><span class="p">[</span><span class="n">dim</span><span class="o">+</span><span class="mi">1</span><span class="p">:])</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">*</span><span class="n">shp</span><span class="p">[:</span><span class="n">dim</span><span class="o">+</span><span class="mi">1</span><span class="p">],</span> <span class="n">repeats</span><span class="p">,</span> <span class="o">*</span><span class="n">shp</span><span class="p">[</span><span class="n">dim</span><span class="o">+</span><span class="mi">1</span><span class="p">:])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">shp</span><span class="p">[:</span><span class="n">dim</span><span class="p">],</span> <span class="n">shp</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span><span class="o">*</span><span class="n">repeats</span><span class="p">,</span> <span class="o">*</span><span class="n">shp</span><span class="p">[</span><span class="n">dim</span><span class="o">+</span><span class="mi">1</span><span class="p">:])</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tinygrad.Tensor.split" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">split</span>


<a href="#tinygrad.Tensor.split" class="headerlink" title="Permanent link">¤</a></h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span class="nf">split</span><span class="p">(</span>
    <span class="n">sizes</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Union" href="https://docs.python.org/3/library/typing.html#typing.Union">Union</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor.int" href="../ops/#tinygrad.Tensor.int">int</a></span><span class="p">,</span> <span class="n"><a class="autorefs autorefs-external" title="typing.List" href="https://docs.python.org/3/library/typing.html#typing.List">List</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor.int" href="../ops/#tinygrad.Tensor.int">int</a></span><span class="p">]],</span> <span class="n">dim</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor.int" href="../ops/#tinygrad.Tensor.int">int</a></span> <span class="o">=</span> <span class="mi">0</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Tuple" href="https://docs.python.org/3/library/typing.html#typing.Tuple">Tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor" href="../#tinygrad.Tensor">Tensor</a></span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents first">

      <p>Splits the tensor into chunks along the dimension specified by <code class="language-python highlight"><span class="n">dim</span></code>.
If <code class="language-python highlight"><span class="n">sizes</span></code> is an integer, it splits into equally sized chunks if possible, otherwise the last chunk will be smaller.
If <code class="language-python highlight"><span class="n">sizes</span></code> is a list, it splits into <code class="language-python highlight"><span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span></code> chunks with size in <code class="language-python highlight"><span class="n">dim</span></code> according to <code class="language-python highlight"><span class="n">size</span></code>.</p>
<p><div class="language-python highlight"><pre><span></span><code><span class="n">t</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">[[</span><span class="mi">0</span> <span class="mi">1</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">2</span> <span class="mi">3</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">4</span> <span class="mi">5</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">6</span> <span class="mi">7</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">8</span> <span class="mi">9</span><span class="p">]]</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="n">split</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">repr</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">split</span><span class="p">]))</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)</span>
<span class="n">array</span><span class="p">([[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)</span>
<span class="n">array</span><span class="p">([[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="n">split</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">split</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">repr</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">split</span><span class="p">]))</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)</span>
<span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span>
       <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)</span>
</code></pre></div></p>

            <details class="quote">
              <summary>Source code in <code>tinygrad/tensor.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1125</span>
<span class="normal">1126</span>
<span class="normal">1127</span>
<span class="normal">1128</span>
<span class="normal">1129</span>
<span class="normal">1130</span>
<span class="normal">1131</span>
<span class="normal">1132</span>
<span class="normal">1133</span>
<span class="normal">1134</span>
<span class="normal">1135</span>
<span class="normal">1136</span>
<span class="normal">1137</span>
<span class="normal">1138</span>
<span class="normal">1139</span>
<span class="normal">1140</span>
<span class="normal">1141</span>
<span class="normal">1142</span>
<span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sizes</span><span class="p">:</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]],</span> <span class="n">dim</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">]:</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Splits the tensor into chunks along the dimension specified by `dim`.</span>
<span class="sd">  If `sizes` is an integer, it splits into equally sized chunks if possible, otherwise the last chunk will be smaller.</span>
<span class="sd">  If `sizes` is a list, it splits into `len(sizes)` chunks with size in `dim` according to `size`.</span>

<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  t = Tensor.arange(10).reshape(5, 2)</span>
<span class="sd">  print(t.numpy())</span>
<span class="sd">  ```</span>
<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  split = t.split(2)</span>
<span class="sd">  print(&quot;\\n&quot;.join([repr(x.numpy()) for x in split]))</span>
<span class="sd">  ```</span>
<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  split = t.split([1, 4])</span>
<span class="sd">  print(&quot;\\n&quot;.join([repr(x.numpy()) for x in split]))</span>
<span class="sd">  ```</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">assert</span> <span class="n">all_int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;does not support symbolic shape </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
  <span class="n">dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_resolve_dim</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sizes</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span> <span class="n">sizes</span> <span class="o">=</span> <span class="p">[</span><span class="nb">min</span><span class="p">(</span><span class="n">sizes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span><span class="o">-</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]),</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">sizes</span><span class="p">))]</span>
  <span class="k">assert</span> <span class="nb">sum</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">],</span> <span class="sa">f</span><span class="s2">&quot;expect sizes to sum exactly to </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span><span class="si">}</span><span class="s2">, but got </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
  <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="n">sl</span><span class="p">]</span> <span class="k">for</span> <span class="n">sl</span> <span class="ow">in</span> <span class="p">[</span><span class="nb">tuple</span><span class="p">([</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">)]</span><span class="o">*</span><span class="n">dim</span> <span class="o">+</span> <span class="p">[</span><span class="nb">slice</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">sizes</span><span class="p">[:</span><span class="n">i</span><span class="p">]),</span> <span class="nb">sum</span><span class="p">(</span><span class="n">sizes</span><span class="p">[:</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]))])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">))])</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tinygrad.Tensor.chunk" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">chunk</span>


<a href="#tinygrad.Tensor.chunk" class="headerlink" title="Permanent link">¤</a></h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span class="nf">chunk</span><span class="p">(</span><span class="n">chunks</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor.int" href="../ops/#tinygrad.Tensor.int">int</a></span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor.int" href="../ops/#tinygrad.Tensor.int">int</a></span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-external" title="typing.List" href="https://docs.python.org/3/library/typing.html#typing.List">List</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor" href="../#tinygrad.Tensor">Tensor</a></span><span class="p">]</span>
</code></pre></div>

    <div class="doc doc-contents first">

      <p>Splits the tensor into <code class="language-python highlight"><span class="n">chunks</span></code> number of chunks along the dimension <code class="language-python highlight"><span class="n">dim</span></code>.
If the tensor size along <code class="language-python highlight"><span class="n">dim</span></code> is not divisible by <code class="language-python highlight"><span class="n">chunks</span></code>, all returned chunks will be the same size except the last one.
The function may return fewer than the specified number of chunks.</p>
<p><div class="language-python highlight"><pre><span></span><code><span class="n">chunked</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">11</span><span class="p">)</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">repr</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">chunked</span><span class="p">]))</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span><span class="mi">10</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="n">chunked</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">repr</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">chunked</span><span class="p">]))</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="n">chunked</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">13</span><span class="p">)</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">repr</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">chunked</span><span class="p">]))</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">11</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)</span>
<span class="n">array</span><span class="p">([</span><span class="mi">12</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">int32</span><span class="p">)</span>
</code></pre></div></p>

            <details class="quote">
              <summary>Source code in <code>tinygrad/tensor.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span>
<span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span>
<span class="normal">1170</span>
<span class="normal">1171</span>
<span class="normal">1172</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">chunk</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">chunks</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Splits the tensor into `chunks` number of chunks along the dimension `dim`.</span>
<span class="sd">  If the tensor size along `dim` is not divisible by `chunks`, all returned chunks will be the same size except the last one.</span>
<span class="sd">  The function may return fewer than the specified number of chunks.</span>

<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  chunked = Tensor.arange(11).chunk(6)</span>
<span class="sd">  print(&quot;\\n&quot;.join([repr(x.numpy()) for x in chunked]))</span>
<span class="sd">  ```</span>
<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  chunked = Tensor.arange(12).chunk(6)</span>
<span class="sd">  print(&quot;\\n&quot;.join([repr(x.numpy()) for x in chunked]))</span>
<span class="sd">  ```</span>
<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  chunked = Tensor.arange(13).chunk(6)</span>
<span class="sd">  print(&quot;\\n&quot;.join([repr(x.numpy()) for x in chunked]))</span>
<span class="sd">  ```</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">assert</span> <span class="n">all_int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;does not support symbolic shape </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
  <span class="k">assert</span> <span class="n">chunks</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;expect chunks to be greater than 0, got: </span><span class="si">{</span><span class="n">chunks</span><span class="si">}</span><span class="s2">&quot;</span>
  <span class="n">dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_resolve_dim</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
  <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span><span class="o">/</span><span class="n">chunks</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="k">else</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">chunks</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">))</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tinygrad.Tensor.squeeze" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">squeeze</span>


<a href="#tinygrad.Tensor.squeeze" class="headerlink" title="Permanent link">¤</a></h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span class="nf">squeeze</span><span class="p">(</span><span class="n">dim</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Optional" href="https://docs.python.org/3/library/typing.html#typing.Optional">Optional</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor.int" href="../ops/#tinygrad.Tensor.int">int</a></span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor" href="../#tinygrad.Tensor">Tensor</a></span>
</code></pre></div>

    <div class="doc doc-contents first">

      <p>Returns a tensor with specified dimensions of input of size 1 removed.
If <code class="language-python highlight"><span class="n">dim</span></code> is not specified, all dimensions with size 1 are removed.</p>
<p><div class="language-python highlight"><pre><span></span><code><span class="n">t</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</code></pre></div></p>

            <details class="quote">
              <summary>Source code in <code>tinygrad/tensor.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1174</span>
<span class="normal">1175</span>
<span class="normal">1176</span>
<span class="normal">1177</span>
<span class="normal">1178</span>
<span class="normal">1179</span>
<span class="normal">1180</span>
<span class="normal">1181</span>
<span class="normal">1182</span>
<span class="normal">1183</span>
<span class="normal">1184</span>
<span class="normal">1185</span>
<span class="normal">1186</span>
<span class="normal">1187</span>
<span class="normal">1188</span>
<span class="normal">1189</span>
<span class="normal">1190</span>
<span class="normal">1191</span>
<span class="normal">1192</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">squeeze</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span><span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Returns a tensor with specified dimensions of input of size 1 removed.</span>
<span class="sd">  If `dim` is not specified, all dimensions with size 1 are removed.</span>

<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  t = Tensor.zeros(2, 1, 2, 1, 2)</span>
<span class="sd">  print(t.squeeze().shape)</span>
<span class="sd">  ```</span>
<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  print(t.squeeze(0).shape)</span>
<span class="sd">  ```</span>
<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  print(t.squeeze(1).shape)</span>
<span class="sd">  ```</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="n">dim</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">dim</span> <span class="k">for</span> <span class="n">dim</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="k">if</span> <span class="n">dim</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">))</span>
  <span class="n">dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_resolve_dim</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
  <span class="k">return</span> <span class="bp">self</span> <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">1</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="n">dim</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="o">+</span><span class="mi">1</span><span class="p">:])</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tinygrad.Tensor.unsqueeze" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">unsqueeze</span>


<a href="#tinygrad.Tensor.unsqueeze" class="headerlink" title="Permanent link">¤</a></h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span class="nf">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor.int" href="../ops/#tinygrad.Tensor.int">int</a></span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor" href="../#tinygrad.Tensor">Tensor</a></span>
</code></pre></div>

    <div class="doc doc-contents first">

      <p>Returns a tensor with a new dimension of size 1 inserted at the specified <code class="language-python highlight"><span class="n">dim</span></code>.</p>
<p><div class="language-python highlight"><pre><span></span><code><span class="n">t</span> <span class="o">=</span> <span class="n">Tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">[[</span><span class="mi">1</span> <span class="mi">2</span> <span class="mi">3</span> <span class="mi">4</span><span class="p">]]</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">[[</span><span class="mi">1</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">2</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">3</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">4</span><span class="p">]]</span>
</code></pre></div></p>

            <details class="quote">
              <summary>Source code in <code>tinygrad/tensor.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1194</span>
<span class="normal">1195</span>
<span class="normal">1196</span>
<span class="normal">1197</span>
<span class="normal">1198</span>
<span class="normal">1199</span>
<span class="normal">1200</span>
<span class="normal">1201</span>
<span class="normal">1202</span>
<span class="normal">1203</span>
<span class="normal">1204</span>
<span class="normal">1205</span>
<span class="normal">1206</span>
<span class="normal">1207</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">unsqueeze</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span><span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Returns a tensor with a new dimension of size 1 inserted at the specified `dim`.</span>

<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  t = Tensor([1, 2, 3, 4])</span>
<span class="sd">  print(t.unsqueeze(0).numpy())</span>
<span class="sd">  ```</span>
<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  print(t.unsqueeze(1).numpy())</span>
<span class="sd">  ```</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_resolve_dim</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">outer</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="n">dim</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">:])</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tinygrad.Tensor.pad2d" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">pad2d</span>


<a href="#tinygrad.Tensor.pad2d" class="headerlink" title="Permanent link">¤</a></h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span class="nf">pad2d</span><span class="p">(</span><span class="n">padding</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Sequence" href="https://docs.python.org/3/library/typing.html#typing.Sequence">Sequence</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor.int" href="../ops/#tinygrad.Tensor.int">int</a></span><span class="p">],</span> <span class="n">value</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor.float" href="../ops/#tinygrad.Tensor.float">float</a></span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor" href="../#tinygrad.Tensor">Tensor</a></span>
</code></pre></div>

    <div class="doc doc-contents first">

      <p>Returns a tensor that pads the last two axes specified by <code class="language-python highlight"><span class="n">padding</span></code> (padding_left, padding_right, padding_top, padding_bottom).
If <code class="language-python highlight"><span class="n">value</span></code> is specified, the tensor is padded with <code class="language-python highlight"><span class="n">value</span></code> instead of <code class="language-python highlight"><span class="mf">0.0</span></code>.</p>
<p><div class="language-python highlight"><pre><span></span><code><span class="n">t</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">9</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">[[[[</span><span class="mi">0</span> <span class="mi">1</span> <span class="mi">2</span><span class="p">]</span>
   <span class="p">[</span><span class="mi">3</span> <span class="mi">4</span> <span class="mi">5</span><span class="p">]</span>
   <span class="p">[</span><span class="mi">6</span> <span class="mi">7</span> <span class="mi">8</span><span class="p">]]]]</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">pad2d</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">value</span><span class="o">=-</span><span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">[[[[</span><span class="o">-</span><span class="n">inf</span> <span class="o">-</span><span class="n">inf</span> <span class="o">-</span><span class="n">inf</span> <span class="o">-</span><span class="n">inf</span> <span class="o">-</span><span class="n">inf</span><span class="p">]</span>
   <span class="p">[</span><span class="o">-</span><span class="n">inf</span> <span class="o">-</span><span class="n">inf</span> <span class="o">-</span><span class="n">inf</span> <span class="o">-</span><span class="n">inf</span> <span class="o">-</span><span class="n">inf</span><span class="p">]</span>
   <span class="p">[</span><span class="o">-</span><span class="n">inf</span>   <span class="mf">0.</span>   <span class="mf">1.</span>   <span class="mf">2.</span> <span class="o">-</span><span class="n">inf</span><span class="p">]</span>
   <span class="p">[</span><span class="o">-</span><span class="n">inf</span>   <span class="mf">3.</span>   <span class="mf">4.</span>   <span class="mf">5.</span> <span class="o">-</span><span class="n">inf</span><span class="p">]</span>
   <span class="p">[</span><span class="o">-</span><span class="n">inf</span>   <span class="mf">6.</span>   <span class="mf">7.</span>   <span class="mf">8.</span> <span class="o">-</span><span class="n">inf</span><span class="p">]]]]</span>
</code></pre></div></p>

            <details class="quote">
              <summary>Source code in <code>tinygrad/tensor.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1209</span>
<span class="normal">1210</span>
<span class="normal">1211</span>
<span class="normal">1212</span>
<span class="normal">1213</span>
<span class="normal">1214</span>
<span class="normal">1215</span>
<span class="normal">1216</span>
<span class="normal">1217</span>
<span class="normal">1218</span>
<span class="normal">1219</span>
<span class="normal">1220</span>
<span class="normal">1221</span>
<span class="normal">1222</span>
<span class="normal">1223</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">pad2d</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">padding</span><span class="p">:</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">value</span><span class="p">:</span><span class="nb">float</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Returns a tensor that pads the last two axes specified by `padding` (padding_left, padding_right, padding_top, padding_bottom).</span>
<span class="sd">  If `value` is specified, the tensor is padded with `value` instead of `0.0`.</span>

<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  t = Tensor.arange(9).reshape(1, 1, 3, 3)</span>
<span class="sd">  print(t.numpy())</span>
<span class="sd">  ```</span>
<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  print(t.pad2d((1, 1, 2, 0), value=-float(&quot;inf&quot;)).numpy())</span>
<span class="sd">  ```</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">slc</span> <span class="o">=</span> <span class="p">[(</span><span class="o">-</span><span class="n">p0</span><span class="p">,</span> <span class="n">s</span><span class="o">+</span><span class="n">p1</span><span class="p">)</span> <span class="k">for</span> <span class="n">p0</span><span class="p">,</span><span class="n">p1</span><span class="p">,</span><span class="n">s</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">padding</span><span class="p">[::</span><span class="mi">2</span><span class="p">],</span> <span class="n">padding</span><span class="p">[</span><span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">])][::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
  <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_slice</span><span class="p">([(</span><span class="mi">0</span><span class="p">,</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span><span class="p">)]]</span> <span class="o">+</span> <span class="n">slc</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-attribute">



<h3 id="tinygrad.Tensor.T" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <span class="doc doc-object-name doc-attribute-name">T</span>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#tinygrad.Tensor.T" class="headerlink" title="Permanent link">¤</a></h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span class="n">T</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor" href="../#tinygrad.Tensor">Tensor</a></span>
</code></pre></div>

    <div class="doc doc-contents first">

      <p><code class="language-python highlight"><span class="o">.</span><span class="n">T</span></code> is an alias for <code class="language-python highlight"><span class="o">.</span><span class="n">transpose</span><span class="p">()</span></code>.</p>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tinygrad.Tensor.transpose" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">transpose</span>


<a href="#tinygrad.Tensor.transpose" class="headerlink" title="Permanent link">¤</a></h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span class="nf">transpose</span><span class="p">(</span><span class="n">dim0</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor" href="../#tinygrad.Tensor">Tensor</a></span>
</code></pre></div>

    <div class="doc doc-contents first">

      <p>Returns a tensor that is a transposed version of the original tensor.
The given dimensions <code class="language-python highlight"><span class="n">dim0</span></code> and <code class="language-python highlight"><span class="n">dim1</span></code> are swapped.</p>
<p><div class="language-python highlight"><pre><span></span><code><span class="n">t</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">[[</span><span class="mi">0</span> <span class="mi">1</span> <span class="mi">2</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">3</span> <span class="mi">4</span> <span class="mi">5</span><span class="p">]]</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">[[</span><span class="mi">0</span> <span class="mi">3</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">1</span> <span class="mi">4</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">2</span> <span class="mi">5</span><span class="p">]]</span>
</code></pre></div></p>

            <details class="quote">
              <summary>Source code in <code>tinygrad/tensor.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1230</span>
<span class="normal">1231</span>
<span class="normal">1232</span>
<span class="normal">1233</span>
<span class="normal">1234</span>
<span class="normal">1235</span>
<span class="normal">1236</span>
<span class="normal">1237</span>
<span class="normal">1238</span>
<span class="normal">1239</span>
<span class="normal">1240</span>
<span class="normal">1241</span>
<span class="normal">1242</span>
<span class="normal">1243</span>
<span class="normal">1244</span>
<span class="normal">1245</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">transpose</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim0</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim1</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Returns a tensor that is a transposed version of the original tensor.</span>
<span class="sd">  The given dimensions `dim0` and `dim1` are swapped.</span>

<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  t = Tensor.arange(6).reshape(2, 3)</span>
<span class="sd">  print(t.numpy())</span>
<span class="sd">  ```</span>
<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  print(t.transpose(0, 1).numpy())</span>
<span class="sd">  ```</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">order</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ndim</span><span class="p">))</span>
  <span class="n">order</span><span class="p">[</span><span class="n">dim0</span><span class="p">],</span> <span class="n">order</span><span class="p">[</span><span class="n">dim1</span><span class="p">]</span> <span class="o">=</span> <span class="n">order</span><span class="p">[</span><span class="n">dim1</span><span class="p">],</span> <span class="n">order</span><span class="p">[</span><span class="n">dim0</span><span class="p">]</span>
  <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="n">order</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tinygrad.Tensor.flatten" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">flatten</span>


<a href="#tinygrad.Tensor.flatten" class="headerlink" title="Permanent link">¤</a></h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span class="nf">flatten</span><span class="p">(</span><span class="n">start_dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end_dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>

    <div class="doc doc-contents first">

      <p>Flattens the tensor by reshaping it into a one-dimensional tensor.
If <code class="language-python highlight"><span class="n">start_dim</span></code> or <code class="language-python highlight"><span class="n">end_dim</span></code> are passed, only dimensions starting with <code class="language-python highlight"><span class="n">start_dim</span></code> and ending with <code class="language-python highlight"><span class="n">end_dim</span></code> are flattened.</p>
<p><div class="language-python highlight"><pre><span></span><code><span class="n">t</span> <span class="o">=</span> <span class="n">Tensor</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">8</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">[</span><span class="mi">0</span> <span class="mi">1</span> <span class="mi">2</span> <span class="mi">3</span> <span class="mi">4</span> <span class="mi">5</span> <span class="mi">6</span> <span class="mi">7</span><span class="p">]</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">start_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">[[</span><span class="mi">0</span> <span class="mi">1</span> <span class="mi">2</span> <span class="mi">3</span><span class="p">]</span>
 <span class="p">[</span><span class="mi">4</span> <span class="mi">5</span> <span class="mi">6</span> <span class="mi">7</span><span class="p">]]</span>
</code></pre></div></p>

            <details class="quote">
              <summary>Source code in <code>tinygrad/tensor.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1247</span>
<span class="normal">1248</span>
<span class="normal">1249</span>
<span class="normal">1250</span>
<span class="normal">1251</span>
<span class="normal">1252</span>
<span class="normal">1253</span>
<span class="normal">1254</span>
<span class="normal">1255</span>
<span class="normal">1256</span>
<span class="normal">1257</span>
<span class="normal">1258</span>
<span class="normal">1259</span>
<span class="normal">1260</span>
<span class="normal">1261</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">flatten</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">start_dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">end_dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Flattens the tensor by reshaping it into a one-dimensional tensor.</span>
<span class="sd">  If `start_dim` or `end_dim` are passed, only dimensions starting with `start_dim` and ending with `end_dim` are flattened.</span>

<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  t = Tensor.arange(8).reshape(2, 2, 2)</span>
<span class="sd">  print(t.flatten().numpy())</span>
<span class="sd">  ```</span>
<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  print(t.flatten(start_dim=1).numpy())</span>
<span class="sd">  ```</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">start_dim</span><span class="p">,</span> <span class="n">end_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_resolve_dim</span><span class="p">(</span><span class="n">start_dim</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_resolve_dim</span><span class="p">(</span><span class="n">end_dim</span><span class="p">)</span>
  <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="n">start_dim</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">prod</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">start_dim</span><span class="p">:</span><span class="n">end_dim</span><span class="o">+</span><span class="mi">1</span><span class="p">]),</span> <span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">end_dim</span><span class="o">+</span><span class="mi">1</span><span class="p">:])</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="tinygrad.Tensor.unflatten" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <span class="doc doc-object-name doc-function-name">unflatten</span>


<a href="#tinygrad.Tensor.unflatten" class="headerlink" title="Permanent link">¤</a></h3>
<div class="language-python doc-signature highlight"><pre><span></span><code><span class="nf">unflatten</span><span class="p">(</span><span class="n">dim</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor.int" href="../ops/#tinygrad.Tensor.int">int</a></span><span class="p">,</span> <span class="n">sizes</span><span class="p">:</span> <span class="n"><a class="autorefs autorefs-external" title="typing.Tuple" href="https://docs.python.org/3/library/typing.html#typing.Tuple">Tuple</a></span><span class="p">[</span><span class="n"><a class="autorefs autorefs-internal" title="tinygrad.tensor.Tensor.int" href="../ops/#tinygrad.Tensor.int">int</a></span><span class="p">,</span> <span class="o">...</span><span class="p">])</span>
</code></pre></div>

    <div class="doc doc-contents first">

      <p>Unflattens dimension <code class="language-python highlight"><span class="n">dim</span></code> of the tensor into multiple dimensions specified by <code class="language-python highlight"><span class="n">sizes</span></code>. <code class="language-python highlight"><span class="n">Tensor</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span></code> is the inverse of this function.</p>
<p><div class="language-python highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">Tensor</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unflatten</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">Tensor</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unflatten</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">Tensor</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">unflatten</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</code></pre></div></p>

            <details class="quote">
              <summary>Source code in <code>tinygrad/tensor.py</code></summary>
              <div class="language-python highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1263</span>
<span class="normal">1264</span>
<span class="normal">1265</span>
<span class="normal">1266</span>
<span class="normal">1267</span>
<span class="normal">1268</span>
<span class="normal">1269</span>
<span class="normal">1270</span>
<span class="normal">1271</span>
<span class="normal">1272</span>
<span class="normal">1273</span>
<span class="normal">1274</span>
<span class="normal">1275</span>
<span class="normal">1276</span>
<span class="normal">1277</span>
<span class="normal">1278</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">unflatten</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> <span class="n">sizes</span><span class="p">:</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span><span class="o">...</span><span class="p">]):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Unflattens dimension `dim` of the tensor into multiple dimensions specified by `sizes`. `Tensor.flatten()` is the inverse of this function.</span>

<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  print(Tensor.ones(3, 4, 1).unflatten(1, (2, 2)).shape)</span>
<span class="sd">  ```</span>
<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  print(Tensor.ones(3, 4, 1).unflatten(1, (-1, 2)).shape)</span>
<span class="sd">  ```</span>
<span class="sd">  ```python exec=&quot;true&quot; source=&quot;above&quot; session=&quot;tensor&quot; result=&quot;python&quot;</span>
<span class="sd">  print(Tensor.ones(5, 12, 3).unflatten(-2, (2, 2, 3, 1, 1)).shape)</span>
<span class="sd">  ```</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_resolve_dim</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
  <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="n">dim</span><span class="p">]</span> <span class="o">+</span> <span class="n">sizes</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="o">+</span><span class="mi">1</span><span class="p">:])</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../creation/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Creation">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Creation
              </div>
            </div>
          </a>
        
        
          
          <a href="../ops/" class="md-footer__link md-footer__link--next" aria-label="Next: Ops">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Ops
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["announce.dismiss", "content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "content.tooltips", "navigation.footer", "navigation.indexes", "navigation.sections", "navigation.expand", "navigation.top", "navigation.path", "search.highlight", "search.suggest", "toc.follow", "toc.integrate"], "search": "../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.fe8b6f2b.min.js"></script>
      
        <script src="../../assets/_markdown_exec_pyodide.js"></script>
      
    
  </body>
</html>